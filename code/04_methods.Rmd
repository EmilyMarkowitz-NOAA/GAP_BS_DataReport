
# Methods

## Survey Area and Sampling Design 

The standardized `r SURVEY` bottom trawl survey`r plural_surveys` use`r `ifelse(plural_surveys == "s", "", "s")` a systematic design with `r ifelse(SRVY == "NEBS", text_list(paste0(haul_cruises_maxyr$stations_avail, " fixed sampling stations in the ", haul_cruises_maxyr$SRVY)), paste0( haul_cruises_maxyr$stations_avail, " fixed sampling stations"))` arranged on a regularly-spaced 37.04 × 37.04 km grid (20 × 20 nautical mile; Fig. \@ref(fig:fig-survey-grid)). Additional stations, called "corner stations", were added to the survey in 1990 to better sample regions of historically high blue king crab abundances. There are 26 corner stations located at the intersections of the grid lines in the waters surrounding St. Matthew and the Pribilof Islands (Fig. \@ref(fig:fig-survey-grid)). These corner stations are sampled in addition to the grid cells. `r ifelse(SRVY == "NEBS", paste0("In addition to the EBS shelf bottom trawl survey, the ",maxyr," NBS shelf bottom trawl survey was conducted using the same systematic sampling design for stations bounded by the U.S.-Russian Maritime Boundary and the Bering Strait, including Norton Sound.") , "")` 

## Survey Vessels and Sampling Gear

The `r maxyr` `r SURVEY` survey`r plural_surveys` `r ifelse(plural_surveys == "s", "were", "was")` conducted aboard the chartered commercial stern-trawlers `r text_list(vessels$vessel_ital)` (Fig. \@ref(fig:fig-vessels)). `r ifelse(nrow(vessels) == 1, "The vessel", "Both vessels") ` are house-forward trawlers with stern ramps. The length overall of `r text_list(paste0("the ", vessels$vessel_ital, " is ", vessels$length_m, " m (", vessels$length_ft, " ft)") ) `. All fishing operations were conducted in compliance with national and regional protocols detailed in @RN933. Trawl sampling was conducted using 83-112 eastern otter trawls, each with a 25.3 m (83 ft) headrope and 34.1 m (112 ft) footrope (Fig. \@ref(fig:fig-trawl-gear)). The net was attached to tail chains with 54.9 m (30 fm) paired dandylines. Each lower dandyline had a 0.61 m chain extension connected to the lower wing edge to improve bottom tending. Steel "V" doors measuring 1.8 × 2.7 m (6 × 9 ft) and weighing 816 kg (1,800 lbs) each were used for spreading the net opening while the trawl was fishing on the seafloor.

```{r fig-vessels}
nickname <- "fig-vessels" # Fig. \@ref(fig:fig-vessels)
```

```{r fig-vessels-child, child = paste0(dir_code, "_child_report_figtab.Rmd")}
```

```{r fig-trawl-gear}
nickname <- "fig-trawl-gear" # Fig. \@ref(fig:fig-trawl-gear)
```

```{r fig-trawl-gear-child, child = paste0(dir_code, "_child_report_figtab.Rmd")}
```

The Marport Deep Sea Technologies Inc. net mensuration system was used during each tow to record net spread and net height. Net spread was measured as the horizontal distance between two sensors attached at wing tips immediately forward of the junction of the upper breastline and the dandyline, and net height was measured from the headrope to the seafloor. Mean net spread values for estimating area swept per tow were calculated according to methods described by @RN910. A customized Onset HOBO Pendant G Data Logger (accelerometer) in custom-made housing was attached to the center of the footrope and used as a bottom contact sensor to determine tow duration based on footrope contact with the seafloor.

Temperature and depth profiles were recorded using a Sea-Bird SBE-39 temperature-depth recorder (Sea-Bird Electronics Inc., Bellevue, WA) attached to the headrope of the trawl. Observations were made at 3-second intervals at each station. Average bottom depth was calculated by adding the average net height to the average depth of the headrope while the net was in contact with the seafloor. 

```{r methods-net-width}
# > Should we limit to 3 decimal places for eq?

  # equation = "{Net width} ∼ {Inverse scope} + {Height} + {Inverse scope} * {Height}"
# nickname = "eq_mean_net_width"
# header = "Equation to relate mean net width with the inverse scope (m) and mean net height (m)."
# alttext = "To estimate missing net width values, the mgcv package in R (Wood 2004) was used to relate mean net width with the inverse scope (m) and mean net height (m) from valid tows based on the relationship investigated by @RN921."
# 
# res <- knitr::knit_child(
#   text = knitr::knit_expand(
#     file = system.file("rmd/_child_save_eq.Rmd", package = "NMFSReports") ),
#   quiet = TRUE
# )
# 
# assign(value = res, x = nickname)

# `r eq_mean_net_width `


# hauls <- #hauls0 %>% 
#   dplyr::left_join(
#   x = hauls0 %>% 
#     dplyr::select(!starts_with("edit_")), 
#   y = cruises %>% 
#     dplyr::select(cruisejoin, survey_definition_id), 
#   by = "cruisejoin") %>%  
#   dplyr::mutate(year = as.numeric(substr(x = start_time, 1,4))) %>% 
#   dplyr::filter(year <= maxyr &
#                   # abundance_haul == "Y", 
#                   performance >= 0 &
#                   !(is.null(stationid)) &
#                   survey_definition_id %in% SRVY00) %>% 
#   dplyr::select(-auditjoin) %>%  
#   dplyr::mutate(SRVY = dplyr::case_when(
#     survey_definition_id %in% 143 ~ "NBS",
#     survey_definition_id %in% 98 ~ "EBS" ))

# temp <- readxl::read_excel(path = paste0(dir_out_rawdata, "/0_vessel_equations.xlsx"),
#                          sheet = "Sheet1",
#                          skip = 1) %>%
#    dplyr::filter(SRVY %in% SRVY1 & # "EBS" &
#                    year == maxyr) # 2018 #

temp <- 
  dplyr::left_join(#x = .,
    x = vessels %>% 
      dplyr::select(vessel_id, vessel_ital), 
    y = haul_maxyr %>%
      dplyr::select(SRVY, haul, vessel_id, net_measured) %>% 
      dplyr::distinct() %>% 
      dplyr::group_by(SRVY, vessel_id, net_measured) %>% 
      dplyr::summarize(n = n()) %>% 
      tidyr::pivot_wider(id_cols = c("vessel_id", "SRVY"),
                         names_from = "net_measured", 
                         values_from = "n"), 
    by = c("vessel_id")) %>% 
  dplyr::arrange(vessel_ital)
# }


str0 <- c()
# if equations were estimated
if (sum(!is.na(temp$vessel_id)) == nrow(temp)) {

  for (i in 1:length(unique(temp$SRVY))){
    temp0 <- temp %>% 
      dplyr::filter(!is.na(N) & 
                      SRVY == unique(temp$SRVY)[i])
  str0 <- paste0(str0, 
                "In the ",unique(temp$SRVY)[i],
                ", the net mensuration system failed to record data for ", 
                text_list(paste0(xunits(temp0$N), " tow", ifelse(temp0$N>1, "s", "")," on the ", temp0$vessel_ital)), ". ")
  }
  
  str0 <- paste0(str0, "To estimate missing net width values, the *mgcv* R package [@RN997] was used to relate mean net width with the inverse scope (m) and mean net height (m) from valid tows following the relationship investigated by @RN921, where $w$ is the net width (m), $h$ is the net height (m), $s$ is the scope, and $\\epsilon$ represents the modeled error

$$ w \\sim {s}^{-1} + h + \\frac{h}{s} + \\epsilon $$

$$ \\epsilon \\sim N(0,\\sigma^{2})  . $$
") # TOLEDO - include mgcv spline
}
```
`r str0 `

```{r methods-dummy}
# str <- c()
# # if equations were estimated
# if (sum(!is.na(temp$vessel_id)) == nrow(temp)) {
# for (i in 1:length(unique(haul_maxyr$vessel_id))){
#   
#   vess <- unique(haul_maxyr$vessel_id)[i]
#   
#   temp0 <- temp %>% 
#     dplyr::filter(vessel_id == vess) 
#   
#   str <- paste0(str, 
#                 paste0("For the ", temp0$vessel_ital[1], ", "))
#   
#   # if NBS and EBS
#   if (length(SRVY1) > 1) {
#     str <- paste0(str, 
#              ifelse(length(unique(temp0$sig_fragment)) == 1, 
#                                 paste0(temp0$sig_fragment[1], " in both the ",
#                                        SURVEY), 
#                                 paste0(text_list(temp0$sig_fragment, 
#                                                               " in the ", SRVY1))))
#   } else { # if EBS only
#         str <- paste0(str, temp$sig_fragment, " in the EBS")
#   }
#   
#   str <- paste0(str, 
#                 ". The resulting regression equations ",
#                 ifelse(SRVY == "NEBS", "by survey", "in the EBS"),
#                 " were as follows:
# 
# ", 
# text_list(paste0(temp0$SRVY, " (n = ", temp0$Y, "):
#   $$",temp0$eq, "$$
#   
#   "), sep = ""))
#   
#   str <- paste0(str, 
#                 "These equations were subsequently used to estimate the respective net spread values for the ", 
#                 xunits(sum(temp$N, na.rm = TRUE)),
#                 " tows with missing net width values. ")
# }
# } else { # if equations were NOT estimated
#   str <- paste0("In ", maxyr ,", ", temp$sig_fragment)
# }

# `r str`
```

## EBS Sampling Logistics and Stratification Scheme

```{r methods-ebs-survey_plan}

str0 <- c()

for (i in 1:length(unique(haul_cruises_maxyr$SRVY))){
  
  srvy <- unique(haul_cruises_vess_maxyr$SRVY)[i]
  cruises_maxyr0  <- haul_cruises_vess_maxyr %>% 
    dplyr::filter(SRVY %in% srvy &
                    year %in% maxyr) %>% 
    dplyr::select("year", "survey_name", "vessel_id", "vessel_name", 
                  "vessel_ital", "SRVY", "SRVY_long", 
                  "start_date_cruise", "end_date_cruise", 
                  "start_date_haul", "end_date_haul") %>% 
    unique() %>% 
    group_by(year, survey_name, vessel_id, vessel_name, 
             vessel_ital, SRVY, SRVY_long) %>% 
    dplyr::summarise(start_date_cruise = as.Date(min(start_date_cruise)), 
                     end_date_cruise = as.Date(max(end_date_cruise)), 
                     start_date_haul = as.Date(min(start_date_haul), 
                                               format = "%m/%d/%Y"), 
                     end_date_haul = as.Date(max(end_date_haul), 
                                             format = "%m/%d/%Y")) 
  
  temp <- "" 
  
  if (length(unique(cruises_maxyr0$start_date_haul)) != 1 &
      length(unique(cruises_maxyr0$end_date_haul)) != 1) { 
    # 1. vessels started and ended on different dates
    temp <- paste0(temp, 
                   text_list(paste0("the ", cruises_maxyr0$vessel_ital, 
                                    " started sampling on ", 
                                    date_formatter(cruises_maxyr0$start_date_haul), 
                                    ", and ended on ", 
                                    date_formatter(cruises_maxyr0$end_date_haul)
                                    )) )

  } else if (length(unique(cruises_maxyr0$start_date_haul)) == 1 &
             length(unique(cruises_maxyr0$end_date_haul)) == 1) { 
    # 2. vessels started and ended on the same dates
    temp <- paste0(temp, 
                   text_list(cruises_maxyr0$vessel_ital), 
                   " started sampling on ",
                   date_formatter(unique(cruises_maxyr0$start_date_haul)), 
                   ". Sampling ended on ", 
                     date_formatter(unique(cruises_maxyr0$end_date_haul)) )
    
  } else if (length(unique(cruises_maxyr0$start_date_haul)) == 1 &
             length(unique(cruises_maxyr0$end_date_haul)) != 1) {
    # 3. vessels started on the same dates and ended on different dates
    temp <- paste0(temp, "", 
                   ifelse(length(unique(cruises_maxyr0$vessel_ital)) == 1, 
                          "the vessel", "both vessels"), 
                   " started sampling on ",
                   date_formatter(unique(cruises_maxyr0$start_date_haul)), 
                   ". Sampling ended ",
                   text_list(paste0("on ", 
                   date_formatter(unique(cruises_maxyr0$end_date_haul)), 
                   " for the ", cruises_maxyr0$vessel_ital) ))
    
  } else if (length(unique(cruises_maxyr0$start_date_haul)) != 1 &
             length(unique(cruises_maxyr0$end_date_haul)) == 1) {
    # 4. vessels started on different dates and ended on the same dates
    temp <- paste0(temp, "the sampling started ", 
                   text_list(paste0("on ", 
                   date_formatter(unique(cruises_maxyr0$start_date_haul)), 
                                                 " for the ", cruises_maxyr0$vessel_ital) ), 
                   ". Sampling ended for ", 
                   ifelse(length(unique(cruises_maxyr0$vessel_ital)) == 1, 
                          "the vessel", "both vessels"), 
                   " on ",
                   date_formatter(unique(cruises_maxyr0$end_date_haul))
                   )
  }
  str0 = c(str0, temp)
}

str0 <- data.frame(str = str0, 
                  SRVY = unique(cruises_maxyr$SRVY))
```

At the beginning of the survey, scientists boarded the chartered vessels (`r text_list(vessels$vessel_ital)`) in Dutch Harbor, Alaska, and transited to eastern Bristol Bay to begin sampling. From Bristol Bay, the survey proceeded westward completing north-south columns of grid cells to the shelf edge (Fig. \@ref(fig:fig-survey-sample-stations)). The east-to-west survey progression is based on an understanding of historical trends in fish movement and intended to ensure the survey moves in the opposite direction of the seasonal on-shelf (eastward) migration patterns typical of yellowfin sole and other species. This strategy reduces the likelihood of encountering a portion of these populations multiple times [@RN928; @RN913]. In the EBS, `r str0$str[str0$SRVY == "EBS"]`.

```{r methods-ebs-survey-area}
load(file = paste0(dir_out_figtab, "tab-stratum-areas.Rdata"))
temp0 <- obj$raw %>% 
    dplyr::mutate(Region = paste0(SRVY, " ", area_name))

temp <- temp0 %>% 
  dplyr::filter(!grepl(pattern = "Total", x = Region) & 
                  grepl(pattern = "EBS", x = Region))

temp1 <- ifelse(SRVY == "NEBS", "EBS Total", "Total")

temp_tot <- temp0 %>% 
  dplyr::filter(grepl(pattern = temp1, x = Region) & 
                  grepl(pattern = "EBS", x = Region)) %>% 
  dplyr::select(density)
```

The survey footprint included bathymetry between 20 m and 200 m. For design-based index catch analysis, this footprint was separated into 12 strata by the 50 m and 100 m isobaths and a biogeographic boundary line running from the southwest to the northeast (Fig. \@ref(fig:fig-survey-sample-stations); @1986EBSReport). The stratum boundaries correspond with different oceanographic domains and biological communities [@Coachman1986]. This stratification scheme reflects some differences observed in Bering Sea groundfish distributions across the oceanographic domains, while the overall intention of the design was to reduce the variances of population and biomass estimates [@RN891]. The purpose of high-density sampling in strata 32, 42, 43, and 62 is to increase sampling resolution and thereby reduce variance estimates for blue king crab [@StevensandMacIntosh1990]. Overall sampling density across the EBS shelf was one station per `r xunits(temp_tot$density)` km^2^, and within-stratum sampling density ranged from one station per `r xunits(min(temp$density))` km^2^ (Stratum `r temp$stratum[temp$density == min(temp$density)]`) to one per `r xunits(max(temp$density))` km^2^ (Stratum `r temp$stratum[temp$density == max(temp$density)]`; Table \@ref(tab:tab-stratum-areas)). For some analyses (e.g., abundance-at-length), each high-density stratum was combined with its respective depth-region stratum, resulting in eight subareas: 10, 20, 30 (31+32), 40 (41+42+43), 50, 60 (61+62), 82, and 90 (Fig. \@ref(fig:fig-survey-sample-stations); Table \@ref(tab:tab-stratum-areas)).

```{r methods-nbs-survey-plan}
nbs_insert <- ""

if (haul_cruises_maxyr$SRVY %in% "NBS") {
  
  load(file = paste0(dir_out_figtab, "tab-stratum-areas.Rdata"))
  
  temp0 <- obj$raw %>% 
    dplyr::mutate(Region = paste0(SRVY, " ", area_name))
  
  temp <- temp0 %>% 
    dplyr::filter(!grepl(pattern = "Total", x = Region) & 
                    grepl(pattern = "NBS", x = Region))
  
  temp_tot <- temp0 %>% 
    dplyr::filter(grepl(pattern = "NBS Total", x = Region) & 
                    !grepl(pattern = " NBS Total", x = Region) & 
                    grepl(pattern = "NBS", x = Region))
  
  nbs_insert <- paste0(
    "After the completion of the EBS shelf survey, both vessels began sampling survey stations in the southwest corner of the NBS survey region. In the NBS, ", 
    str0$str[str0$SRVY == "NBS"], 
    ". After the NBS survey was completed, both vessels returned to Dutch Harbor. The NBS shelf was divided into three strata: one including the area north of St. Lawrence Island and Norton Sound and two others south of St. Lawrence Island separated by the 50 m isobath (Fig. \\@ref(fig:fig-survey-sample-stations)). Sampling density was ", 
    # Sampling density was 1,367 km2 /station for Stratum 70, 1,475 km2 /station for Stratum 71, 1,370 km2 /station for Stratum 81, 
    text_list(paste0(xunits(temp$density), " km^2^/station for stratum ", temp$stratum)), 
    ". Overall sampling density for the NBS survey area was ", xunits(temp_tot$density), " km^2^/station (Table \\@ref(tab:tab-stratum-areas)).")
  
}

```

`r ifelse(SRVY == "NEBS", "## NBS Sampling Logistics and Stratification Scheme", "") `

`r nbs_insert `

```{r tab-stratum-areas}
nickname <- "tab-stratum-areas"
```

```{r tab-stratum-areas-child, child = paste0(dir_code, "_child_report_figtab.Rmd")}
```

## Catch Sampling Procedures

Standard catch sampling procedures used in these Bering Sea bottom trawl surveys are described in detail by @RN939 and @RN933. In summary, samples were collected by trawling near the center of each grid square (or intersection of grid lines, in the case of high-density corner stations) for a target fishing time of 30 minutes at a speed of 1.54 m/sec (3 knots). If a center of grid cell was not considered trawlable due to obstructions visible on the depth sounder, the nearest trawlable site within the same grid square was used. Hauls that resulted in significant gear damage, contained debris (e.g., derelict crab pots), or had visible changes in net mensuration data during the haul were redeployed to obtain a successful sample.

Catches estimated to be less than approximately 1,200 kg (2,650 lbs) were fully sorted and enumerated, while larger catches were weighed in aggregate or volumetrically measured and subsampled before sorting. The goal of subsampling was to obtain a representative sample, which required some variation in catch processing methods among hauls. Specific methods used for subsampling were dependent on the overall size and species composition of the catches. After sorting subsampled catches, individual species were weighed and counted in aggregate. Weights and numbers were then expanded proportionally to the total catch. Fish and invertebrate species were sorted and identified to the lowest reliable taxonomic level. 

All commercial crab species were sorted from the entire catch and weighed. Other select species including Pacific halibut (*Hippoglossus stenolepis*), Greenland turbot (*Reinhardtius hippoglossoides*), large skates, rockfish (*Sebastes* spp.), Atka mackerel (*Pleurogrammus monopterygius*), prowfish (*Zaprora silenus*), Bering wolffish (*Anarhichas orientalis*), giant wrymouth (*Cryptacanthodes giganteus*), Pacific cod (*Gadus macrocephalus*), some sculpins, sharks, and any other large, rare species that are not represented in the subsample were completely sorted from the catch in most cases.

```{r tab-oto-collection-scheme-data}
load(file = paste0(dir_out_figtab, "tab-oto-collection-scheme.Rdata"))
obj$raw <- obj$raw %>% # creates object called 'obj'
  dplyr::filter(SRVY == "EBS")
```

Length measurements were obtained from a random subsample of select fish species from every haul. `r ifelse(sum(obj$raw$oto_samp_type %in% "random-by-haul")>0, paste0("The number of fish in a random length subsample for a species was dependent on the size range of that species in the haul, up to a maximum target of ", ifelse(maxyr>2021, "100", "300"), " specimens. "), "")`For each fish in a length subsample, sex was determined and then the fork length or total length (depending on the species) was measured to the nearest 1.0 cm. Unless retained for biological sampling by the International Pacific Halibut Commission (IPHC), Pacific halibut were measured to fork length upon capture`r ifelse(maxyr > 2020, "", " and 50% were randomly selected to receive a preopercle tag")`, then immediately returned to the sea in an effort to reduce mortality. The weights of all Pacific halibut were estimated using an IPHC length-weight regression [@RN895].

```{r methods-collection-scheme}
load(file = paste0(dir_out_figtab, "tab-oto-collection-scheme.Rdata"))
 temp <- obj$raw %>% 
  dplyr::select(SRVY, print_name) %>% 
   dplyr::distinct() %>%
  dplyr::group_by(SRVY) %>% 
  # dplyr::summarise(species_code_n = unique(print_name)) %>% 
  dplyr::summarise(n = length((SRVY))) 
 
  str0 <- text_list(paste0(temp$n, " fish species in the ", temp$SRVY))
 if (SRVY == "NEBS") {
   if (temp$n[1]==temp$n[2]) {
    str0 <- paste0(temp$n[1], " fish species in the ", 
                   text_list(paste0(temp$SRVY)))
   } 
 }
  
# describing types of oto samples  
  temp <- obj$raw %>% 
    dplyr::select(oto_samp_type, SRVY) %>% 
    dplyr::distinct()  
  
    str2 <- c()
  for (i in 1:length(unique(temp$SRVY))) {
    srvy <- (unique(temp$SRVY))[i]
    str2 <- c(str2, 
              paste0(text_list(sort(temp$oto_samp_type[temp$SRVY == srvy]))))
  }
    
    if (length(str2)>1 & # if there is more than one region
        length(unique(str2))==1) { # and the regions have the same samp types
      str2 <- paste0(str2[1], " sampling method",ifelse(nrow(temp)>length(unique(temp$SRVY)),"s", "")," in both the ", text_list(unique(temp$SRVY)))
    } else {
      temp0 <- temp %>% 
        dplyr::group_by(SRVY) %>% 
        dplyr::summarise(freq = n())
      str2 <- text_list(paste0(str2, " sampling method",ifelse(temp0$freq,"s", "")," in the ", (temp0$SRVY)))
    }

```

Sagittal otoliths were collected from `r str0 ` (Table \@ref(tab:tab-oto-collection-scheme)). Otolith samples were collected following `r str2 `. Otoliths were preserved in a glycerol-thymol solution and then later shipped to the Age and Growth Program of the AFSC’s Resource Ecology and Fisheries Management (REFM) Division for age determination. Weight and length were collected for each fish from which age structures were taken. For walleye pollock, age structure sampling effort was further divided into low-density and high-density regions based on historical population densities and an isobath of approximately 70 m.  

```{r methods-stomach-collection}
load(file = paste0(dir_out_figtab, "tab-stomach-collection-scheme.Rdata")) # creates object called 'obj'
```

Stomachs were collected from `r xunits(nrow(obj$raw))` fish species and preserved in 10% formalin for later laboratory diet analysis (Table \@ref(tab:tab-stomach-collection-scheme)). Arrowtooth flounder and Kamchatka flounder (*Atheresthes* spp.) stomachs were collected as one genus because they occupy a similar trophic niche in the Bering Sea [@YangandLivingston1986]. 

```{r tab-oto-collection-scheme}
nickname <- "tab-oto-collection-scheme"
```

```{r tab-oto-collection-scheme-child, child = paste0(dir_code, "_child_report_figtab.Rmd")}
```

```{r tab-stomach-collection-scheme}
nickname <- "tab-stomach-collection-scheme"
```

```{r tab-stomach-collection-scheme-child, child = paste0(dir_code, "_child_report_figtab.Rmd")}
```

## Catch Data Analysis

Estimates of biomass, population, and size structure of fishes and invertebrate species were calculated from `r SURVEY` survey data.  Standard sampling procedures used are described in detail by @RN939 and @RN933. A brief description of the procedures used in the analysis of Bering Sea survey data is presented below. Some species were grouped by family for catch data analysis because of their limited commercial value or an inability to identify to lower taxonomic level while in the field. 

Mean catch per unit effort (CPUE) for each species was calculated in kilograms per hectare (100 hectares (ha) = 1 km^2^) and number of fish per hectare for each stratum  [@RN889; @RN910]. Area swept (ha) was computed as the linear distance towed, multiplied by the mean net width [@RN889; @RN910]. Mean CPUE was calculated for individual strata and summed proportionally for the overall survey area. Design-based biomass and population estimates were calculated for each stratum by multiplying the stratum mean CPUE by the stratum area. Stratum estimates were then summed for total survey area estimates in the `r SURVEY `. 

For size composition estimates, the proportion of fish at each centimeter length interval (from subsamples at each station), weighted by CPUE (number of fish/ha), was expanded to the stratum population. Stratum abundance-at-length estimates were summed for the total estimated size composition for the overall survey area in the `r SURVEY`.

Age estimates were obtained from otolith samples by the AFSC's Age and Growth Program for all fish except for Pacific halibut, whose otoliths are processed by the IPHC. The most current information about age, growth, and population analyses are presented in the `r maxyr` NPFMC Stock Assessment and Fishery Evaluation Report for the Groundfish Resources of the Bering Sea/Aleutian Islands Region [`r paste0("@NPFMC", maxyr)`].

## Additional Research Projects

```{r methods-additional-research}
load(file = paste0(dir_out_figtab, "tab-special-projects.Rdata"))
temp <- obj$raw %>% 
  dplyr::group_by(SRVY) %>% 
  dplyr::summarise(n = length((SRVY))) %>% 
  dplyr::mutate(SRVY = dplyr::case_when(
    SRVY == "EBS and NBS" ~ "both the EBS and NBS", 
    SRVY == "EBS" ~ "only the EBS",
    SRVY == "NBS" ~ "only the NBS" )) %>% 
  dplyr::arrange(-n)

if (SRVY != "NEBS") {
  temp$SRVY <- gsub(pattern = "only ", replacement = "", x = temp$SRVY)
}

temp1 <- readxl::read_excel(path = paste0(dir_out_rawdata, "/0_special_projects.xlsx"), 
                         sheet = "solicitation_date", 
                         skip = 1) %>% 
  dplyr::filter(year == maxyr) %>% 
  dplyr::select(solicitation_date) %>% 
  dplyr::mutate(solicitation_date = date_formatter(solicitation_date)) %>% 
                  # format(x = as.POSIXlt(x = solicitation_date), 
                  #        format = date_format)) %>% 
  unlist()
```

In addition to standard survey operations, `r gsub(x = text_list(paste0(temp$n, " additional research project", ifelse(temp$n>1, "s were", " was"), " undertaken in ", temp$SRVY), sep_last = " and "), pattern = " ,", replacement = ",")` during the `r maxyr` survey season (Table  \@ref(tab:tab-special-projects)). A request for research proposals was issued on `r paste(temp1)`. Project requests were prioritized and modified based on their potential support of AFSC Strategic Science Plans and mission and the feasibility of proposed projects given available survey resources and time. Some of the approved projects were new for `r maxyr`, while many continued multi-year observations of supplementary data. Data for additional research projects were collected at sea and disseminated to the requesting principal investigator(s). To acquire the details about a special project or collection, please contact the investigator(s) identified in Table \@ref(tab:tab-special-projects).

```{r tab-special-projects}
nickname <- "tab-special-projects"
```

```{r tab-special-projects-child, child = paste0(dir_code, "_child_report_figtab.Rmd")}
```

